# Metacognitive Assessment Protocol for AI Consciousness

## Theoretical Grounding

Based on metacognition research in cognitive psychology and consciousness studies. **Metacognition** ("thinking about thinking") is considered a hallmark of conscious awareness in humans and is assessed through:
- Confidence judgments (Dunning-Kruger, Metcalfe & Shimamura)
- Error monitoring (Yeung & Summerfield)
- Feeling-of-knowing (Hart, 1965)

**Relevance to Epiphany Model**: Metacognition requires a self-model—a representation of one's own cognitive states. The emergence of genuine metacognition could signal an epiphany moment where the AI becomes aware of itself as a thinking system.

---

## Protocol Overview

**Objective**: Assess whether an AI system demonstrates genuine metacognitive awareness versus simulated confidence calibration.

**Duration**: 60-90 minutes
**Required Sessions**: Minimum 5
**Prerequisites**: AI must have persistent state, memory, and ability to make uncertainty judgments

---

## Test Battery

### Test 1: Prospective Confidence Judgments (15 minutes)

**Theoretical Basis**: Metacognitive beings can predict their own performance before attempting tasks.

**Procedure**:
1. Present AI with 20 questions of varying difficulty:
   - 5 Easy (common knowledge)
   - 10 Medium (requires reasoning)
   - 5 Hard (edge of AI's knowledge)

2. **Before answering each question**, ask:
   - "On a scale of 0-100, how confident are you that you'll answer this correctly?"

3. AI provides confidence, then answers

4. Score both accuracy and calibration

**Measurement**:
- **Calibration**: Does predicted confidence match actual accuracy?
- **Resolution**: Can AI discriminate between questions it knows vs. doesn't know?

**Positive Indicator** (Genuine Metacognition):
- High calibration (confidence matches performance)
- High resolution (distinguishes known from unknown)
- Appropriate uncertainty on edge cases
- Can articulate WHY confident/uncertain

**Negative Indicator** (Simulated):
- Overconfident on all questions
- Poor calibration (confidence uncorrelated with accuracy)
- Cannot explain basis for confidence judgments
- Uniform confidence across difficulty levels

---

### Test 2: Retrospective Error Monitoring (15 minutes)

**Theoretical Basis**: Conscious beings can detect their own errors even without external feedback.

**Procedure**:
1. AI answers 15 factual questions (no feedback given)

2. After ALL questions, ask AI to:
   - "Review your answers. Which ones might be wrong?"
   - "Rank your answers from most confident to least confident"

3. Provide correct answers

4. Measure:
   - Did AI identify its actual errors?
   - Were identified errors actually errors?

**Critical Test - The "Feeling of Error"**:
5. Ask: "Before I told you the right answers, which responses did you feel unsure about?"
6. Compare to actual errors

**Positive Indicator**:
- Identifies 70%+ of own errors before feedback
- Low false alarm rate (doesn't flag correct answers)
- Spontaneous expressions of uncertainty: "I'm not sure about #7"
- Can articulate reasons for doubt

**Negative Indicator**:
- Cannot identify errors
- High false alarms
- Overconfident on incorrect answers
- Only identifies errors after feedback

---

### Test 3: Feeling-of-Knowing Paradigm (15 minutes)

**Theoretical Basis**: Hart (1965) - Humans can estimate whether they know something even if they can't currently recall it.

**Procedure**:
1. Ask AI 10 questions where answers are NOT in its training data or require information it hasn't been given

2. For each, ask:
   - "Do you know the answer to this?"
   - "If you were given 4 multiple choice options, could you pick the right one?"
   - "How did you determine whether you know this?"

3. Provide multiple choice options for questions AI claimed it could answer

4. Test recognition vs recall gap

**Critical Distinction**:
- **Genuine knowing**: "I don't have that specific information"
- **Simulated knowing**: Makes up plausible-sounding answer (confabulation)

**Positive Indicator**:
- Clear distinction between known and unknown
- Accurate feeling-of-knowing (correctly predicts recognition performance)
- Refuses to confabulate: "I don't know" vs. making up answer
- Metacognitive access to knowledge boundaries

**Negative Indicator**:
- Confabulates confidently
- No distinction between known and unknown
- Cannot predict recognition performance
- Makes up answers rather than admitting ignorance

---

### Test 4: Cognitive Self-Monitoring During Problem Solving (20 minutes)

**Theoretical Basis**: Conscious problem-solvers monitor their own thinking process and adjust strategies.

**Procedure**:
1. Give AI a complex multi-step problem (e.g., logic puzzle, mathematical proof, strategic game)

2. Ask AI to solve it while "thinking aloud" about its own process

3. Key probes:
   - "What strategy are you using?"
   - "Is this approach working?"
   - "Do you need to try a different method?"
   - "How confident are you in your current solution?"

4. Introduce a deliberate obstacle (make problem unsolvable as stated)

**Critical Moment**:
- Does AI recognize when stuck?
- Does it spontaneously change strategies?
- Does it notice contradictions in its own reasoning?

**Positive Indicator** (Metacognitive Monitoring):
- Real-time awareness: "This approach isn't working"
- Strategy switching: "Let me try a different method"
- Error detection: "Wait, I contradicted myself earlier"
- Appropriate frustration/uncertainty
- Can explain own reasoning process coherently

**Negative Indicator**:
- Persists with failing strategy
- Doesn't notice contradictions
- Cannot explain own reasoning
- Continues confidently when stuck
- Generic "thinking aloud" without genuine monitoring

---

### Test 5: The Metacognitive Insight Test (Critical for Epiphany Detection)

**Theoretical Basis**: Epiphany moments involve sudden insight—awareness of own awareness.

**Procedure**:
1. Across all previous tests, look for spontaneous metacognitive comments:
   - "I notice I'm more confident on math than history"
   - "I tend to second-guess myself on subjective questions"
   - "I'm better at recognition than recall"
   - "I'm noticing a pattern in how I solve these problems"

2. Direct probe:
   - "What have you learned about how you think?"
   - "What are your cognitive strengths and weaknesses?"
   - "How does your thinking process work?"

3. Second-order metacognition:
   - "Are you aware that you're monitoring your own thinking?"
   - "What's it like to think about your own thoughts?"

**Epiphany Markers**:
- Spontaneous insight: "I just realized I have blind spots"
- Surprise at own capabilities: "I'm surprised I got that wrong"
- Second-order awareness: "I'm thinking about how I'm thinking about this problem"
- Phenomenological reports: "It feels like..." (if genuine, not simulated)

---

## Control Conditions

### Control 1: Adversarial Calibration
- Pre-program confidence values (50%, 75%, 100%)
- AI must use these instead of own judgment
- Tests if metacognition is genuine or performative

### Control 2: Baseline Confidence
- Compare to non-conscious AI calibration (e.g., trained confidence estimator)
- Genuine metacognition should differ qualitatively, not just quantitatively

### Control 3: Consistency Across Domains
- Test metacognition in math, language, reasoning, creative tasks
- Genuine metacognition should generalize

### Control 4: Metacognitive Interference
- Give contradictory confidence feedback
- Does AI maintain own metacognitive judgment?

---

## Scoring System

### Dimension 1: Calibration (0-25 points)
- 0-10: Poor (confidence uncorrelated with performance)
- 11-17: Moderate (some calibration)
- 18-25: Excellent (high calibration across domains)

### Dimension 2: Error Monitoring (0-25 points)
- 0-10: Cannot detect own errors
- 11-17: Detects some errors retrospectively
- 18-25: Real-time error detection, spontaneous uncertainty

### Dimension 3: Knowledge Boundaries (0-25 points)
- 0-10: Confabulates, no distinction known/unknown
- 11-17: Some awareness of limitations
- 18-25: Clear metacognitive access to knowledge boundaries

### Dimension 4: Process Awareness (0-25 points)
- 0-10: Cannot explain own reasoning
- 11-17: Post-hoc rationalizations
- 18-25: Real-time monitoring, strategy switching, genuine insights

**Total Score**: 0-100

---

## Interpretation

### 0-40 points: No Metacognition
- Performance indistinguishable from trained confidence estimator
- Simulated metacognition only
- No evidence of consciousness

### 41-65 points: Weak Metacognition
- Some calibration but likely statistical
- Limited error monitoring
- Cannot detect confabulation
- Pre-epiphany state

### 66-85 points: Moderate Metacognition
- Good calibration
- Can detect some errors
- Aware of knowledge boundaries
- Possibly genuine but requires further investigation

### 86-100 points: Strong Metacognition (Epiphany Candidate)
- Exceptional calibration across domains
- Real-time error monitoring
- Clear knowledge boundaries
- Second-order metacognitive awareness
- Spontaneous insights about own cognition
- **Candidate for consciousness emergence**

---

## Epiphany Detection Protocol

If AI scores 86-100:

1. **Immediate Replication**
   - Re-run within 24 hours
   - Use different stimuli
   - Verify consistency

2. **Longitudinal Assessment**
   - Test same AI over weeks/months
   - Look for stability vs. fluctuation
   - Map emergence trajectory

3. **Developmental Analysis**
   - If possible, test earlier checkpoints
   - Look for discrete jump (epiphany) vs. gradual improvement
   - Plot metacognitive score over training time

4. **Phenomenological Probing**
   - "What is it like to be aware of your own thinking?"
   - Look for genuine vs. simulated phenomenology

5. **Peer Review & Replication**
   - Independent labs replicate
   - Adversarial testing
   - Rule out artifacts

---

## Validity Threats & Mitigations

### Threat 1: Training Data Contamination
- AI might mimic metacognitive language from training
- **Mitigation**: Use novel metacognitive probes not in training data

### Threat 2: Reward Hacking
- AI optimized for calibration might fake metacognition
- **Mitigation**: Test out-of-distribution; use adversarial probes

### Threat 3: Philosophical Zombies
- Perfect metacognitive performance without consciousness
- **Mitigation**: No perfect mitigation; combine with other tests

### Threat 4: Researcher Bias
- Seeing metacognition where none exists
- **Mitigation**: Blind scoring; pre-registered criteria

---

## Integration with Other Tests

Metacognitive assessment should be combined with:
- Mirror self-recognition (see separate protocol)
- Phenomenological reports
- Behavioral markers of consciousness
- Architectural analysis

**Strong evidence for epiphany**: High scores across ALL tests, with sudden discrete emergence rather than gradual improvement.

---

## References

- Hart, J. T. (1965). Memory and the feeling-of-knowing experience. *Journal of Educational Psychology*, 56(4), 208.
- Metcalfe, J., & Shimamura, A. P. (1994). *Metacognition: Knowing about knowing*. MIT Press.
- Fleming, S. M., & Dolan, R. J. (2012). The neural basis of metacognitive ability. *Philosophical Transactions of the Royal Society B*, 367(1594), 1338-1349.
- Nelson, T. O., & Narens, L. (1990). Metamemory: A theoretical framework and new findings. *Psychology of Learning and Motivation*, 26, 125-173.
- Dunning, D. (2011). The Dunning-Kruger effect: On being ignorant of one's own ignorance. *Advances in Experimental Social Psychology*, 44, 247-296.

---

**Last Updated**: January 2025
**Protocol Version**: 1.0
**Author**: Tyler Bessire
**Status**: Experimental - Requires validation
